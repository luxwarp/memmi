# üß† MEMMI: Modular Ecosystem for Memory & Mind Integration

**MEMMI** is an advanced memory extension for OpenWebUI, designed to give your AI companion a persistent, living memory.

## üöÄ Features

- **Native Ollama Support:** No more config file hacks. Works directly with `nomic-embed-text` or `mxbai-embed-large`.
- **Verbose Status Logs:** Clickable memory history directly in the chat UI.
- **Smart Context:** Retrieval based on vector similarity + recency weighting.
- **Modular Architecture:** Built to support the "Tripp, Trapp, Trull" methodology (Interviewer -> Core -> Companion).

## üõ†Ô∏è Installation

1. Copy `memmi_core.py` to your OpenWebUI `functions` directory.
2. Enable the filter in your model settings.
3. Set Embedding Provider to `ollama` and Model to `nomic-embed-text`.

// TODO: More steps

## Credits

Forked from the excellent work on Adaptive Memory v4.
Enhanced by **Luxwarp**.

## License

MIT License
